{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6417729e68f49b9c4d452c1c9d02a130ac5a82e4"
   },
   "source": [
    "## Summary\n",
    "\n",
    "We face the problem of predicting tweets sentiment. \n",
    "We have coded the text as Bag of Words and applied an SVM model. We have built a pipeline to check different hyperparameters using cross-validation. At the end, we have obtained a good model which achieve an AUC of **0.92** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8310471e33b2d232b59c984af7bb3c3c1a149ea9"
   },
   "source": [
    "## Data loading and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "d5db572f-3b58-42a5-979a-464769d52524",
    "_uuid": "db376733d0954ea531a81ee31675624c5968706f"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "dc75bb24602b33c808c542869a46c21b22d2de97"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7da2f279fe6e7975a28c9e29188d3b3f3657c96d"
   },
   "source": [
    "We take only the tweets we are very confident with. We use the BeautifulSoup library to process html encoding present in some tweets because scrapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "945afdde0159f1c50f29fc2fc51f0e851df09069"
   },
   "outputs": [],
   "source": [
    "data_clean = data.copy()\n",
    "data_clean = data_clean[data_clean['airline_sentiment_confidence'] > 0.65]\n",
    "data_clean['sentiment'] = data_clean['airline_sentiment'].\\\n",
    "    apply(lambda x: 1 if x=='negative' else 0)\n",
    "\n",
    "data_clean['text_clean'] = data_clean['text'].apply(lambda x: BeautifulSoup(x, \"lxml\").text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "122f502b795abd17e7ced5e43e0cfc8013ecea93"
   },
   "source": [
    "We are going to distinguish two cases: tweets with negative sentiment and tweets with non-negative sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "06bb2178ef654e498218259f7100b608cd7d9057"
   },
   "outputs": [],
   "source": [
    "data_clean['sentiment'] = data_clean['airline_sentiment'].apply(lambda x: 1 if x=='negative' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "89f09d3bc98e3b86e3031a413f34980509c6a27c"
   },
   "outputs": [],
   "source": [
    "data_clean = data_clean.loc[:, ['text_clean', 'sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "_uuid": "6691b88792fa3177f678ccf5bef19be4c28cbfeb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text_clean  sentiment\n",
       "0                @VirginAmerica What @dhepburn said.          0\n",
       "2  @VirginAmerica I didn't today... Must mean I n...          0\n",
       "3  @VirginAmerica it's really aggressive to blast...          1\n",
       "4  @VirginAmerica and it's a really big bad thing...          1\n",
       "5  @VirginAmerica seriously would pay $30 a fligh...          1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e147eb7acd93b7d0823d904fcc9650e8efe716b0"
   },
   "source": [
    "## Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3c6a57e18082c9bf25771ef9228e82c7deb3880d"
   },
   "source": [
    "We split the data into training and testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "16aa7f48608a80c97a72026c2fc6f8a46d786e52"
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data_clean, test_size=0.2, random_state=1)\n",
    "X_train = train['text_clean'].values\n",
    "X_test = test['text_clean'].values\n",
    "y_train = train['sentiment']\n",
    "y_test = test['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "94ee1c6f7a6d07b2c1efd77736d26967cfa3c30c"
   },
   "outputs": [],
   "source": [
    "def tokenize(text): \n",
    "    tknzr = TweetTokenizer()\n",
    "    return tknzr.tokenize(text)\n",
    "\n",
    "def stem(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "en_stopwords = set(stopwords.words(\"english\")) \n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer = 'word',\n",
    "    tokenizer = tokenize,\n",
    "    lowercase = True,\n",
    "    ngram_range=(1, 1),\n",
    "    stop_words = en_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1f77a8efe0bf0d35469246dd8b023a0873c22dab"
   },
   "source": [
    "We are going to use cross validation and grid search to find good hyperparameters for our SVM model. We need to build a pipeline to don't get features from the validation folds when building each training model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "767434698ce8b073e85944a825b769c421435faf"
   },
   "outputs": [],
   "source": [
    "kfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "342d8284602c5c70b2c4670b594167a21b23ff01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "pipeline_svm = make_pipeline(vectorizer, \n",
    "                            SVC(probability=True, kernel=\"linear\", class_weight=\"balanced\"))\n",
    "\n",
    "grid_svm = GridSearchCV(pipeline_svm,\n",
    "                    param_grid = {'svc__C': [0.01, 0.1, 1]}, \n",
    "                    cv = kfolds,\n",
    "                    scoring=\"roc_auc\",\n",
    "                    verbose=1,   \n",
    "                    n_jobs=-1) \n",
    "\n",
    "grid_svm.fit(X_train, y_train)\n",
    "grid_svm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3fd368a207be22b65227b63f5c1afef97a90ebdb"
   },
   "outputs": [],
   "source": [
    "grid_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d0423162776e00f47bc57b58fa3ddcfd96224905"
   },
   "outputs": [],
   "source": [
    "grid_svm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2d4eefec9996c350185600e50f06f1f822a0a895"
   },
   "outputs": [],
   "source": [
    "def report_results(model, X, y):\n",
    "    pred_proba = model.predict_proba(X)[:, 1]\n",
    "    pred = model.predict(X)        \n",
    "\n",
    "    auc = roc_auc_score(y, pred_proba)\n",
    "    acc = accuracy_score(y, pred)\n",
    "    f1 = f1_score(y, pred)\n",
    "    prec = precision_score(y, pred)\n",
    "    rec = recall_score(y, pred)\n",
    "    result = {'auc': auc, 'f1': f1, 'acc': acc, 'precision': prec, 'recall': rec}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e198da79985925a42874f5cda7ba680c442525bf"
   },
   "source": [
    "Let's see how the model (with the best hyperparameters) works on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ea0bdcdb5a1e107a0105c5e328677d40ad89d6db"
   },
   "outputs": [],
   "source": [
    "report_results(grid_svm.best_estimator_, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ecbf7d2be3498dca42cb09a1413f7bef2b7df7d8"
   },
   "outputs": [],
   "source": [
    "def get_roc_curve(model, X, y):\n",
    "    pred_proba = model.predict_proba(X)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y, pred_proba)\n",
    "    return fpr, tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d8d33164b7da2236ebbdd62f34ec86c2a4bc1bb4"
   },
   "outputs": [],
   "source": [
    "roc_svm = get_roc_curve(grid_svm.best_estimator_, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "46bcb5b9bc9d05c6919a0d21e0b38fdd9d40bb38"
   },
   "outputs": [],
   "source": [
    "fpr, tpr = roc_svm\n",
    "plt.figure(figsize=(14,8))\n",
    "plt.plot(fpr, tpr, color=\"red\")\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Roc curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "68756443ecc129570a64b223773954ff24f3dcad"
   },
   "source": [
    "Let's see if our model has some bias or variance problem ploting its learning curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fe9b9e526eee29a850c771dd60a4082cd5e742f5"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores = \\\n",
    "    learning_curve(grid_svm.best_estimator_, X_train, y_train, cv=5, n_jobs=-1, \n",
    "                   scoring=\"roc_auc\", train_sizes=np.linspace(.1, 1.0, 10), random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "874e62b51ff7f2647a32a7e555fe7ce9f39339ba"
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(X, y, train_sizes, train_scores, test_scores, title='', ylim=None, figsize=(14,8)):\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f6e08a90e079531c58fb5ac0e80b7a5a3eb12405"
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(X_train, y_train, train_sizes, \n",
    "                    train_scores, test_scores, ylim=(0.7, 1.01), figsize=(14,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0fea553a090c2a8fae1b63301eb801b511c564ac"
   },
   "source": [
    "It looks like there isn't a big bias or variance problem, but it is clear that our model would work better with more data:. if we can get more labeled data the model performance will increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7b5371632eea574f8b5222cc78ea5444db4ef4e8"
   },
   "source": [
    "## Examples\n",
    "\n",
    "We are going to apply the obtained machine learning model to some example text. If the output is **1** it means that the text has a negative sentiment associated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9431f7ed32d33061fa33a3d3dbaf2cfb5ec9fc39"
   },
   "outputs": [],
   "source": [
    "grid_svm.predict([\"flying with @united is always a great experience\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4f0ebef54761e222f280e376da06a07f740316a4"
   },
   "outputs": [],
   "source": [
    "grid_svm.predict([\"flying with @united is always a great experience. If you don't lose your luggage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2eaa07ea2e2de41f3d1a35c6d819f91e7f051db4"
   },
   "outputs": [],
   "source": [
    "grid_svm.predict([\"I love @united. Sorry, just kidding!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f958d51248448385ec952caac63c856bcb90dda7"
   },
   "outputs": [],
   "source": [
    "grid_svm.predict([\"@united very bad experience!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ae14843b291e486be7a6564f9af271ffd41f1f02"
   },
   "outputs": [],
   "source": [
    "grid_svm.predict([\"@united very bad experience!\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
